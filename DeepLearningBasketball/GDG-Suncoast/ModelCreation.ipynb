{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelCreation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJRZ3q+rTAxmxGkClHuQXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehennis/Blog/blob/master/DeepLearningBasketball/GDG-Suncoast/ModelCreation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GDG Suncoast: Model Creation"
      ],
      "metadata": {
        "id": "eZrSHYKmWN4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "45DymIZlWDfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Neural Network Architecture"
      ],
      "metadata": {
        "id": "1FHv4rHGW1Bq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters\n",
        "**Sequential** ([Documantaion](https://keras.io/api/models/sequential/)): A sequential network runs linearly through the layers.  \n",
        "**Dense** ([Documentaion](https://keras.io/api/layers/core_layers/dense/)): A densely connected network layer. This is the standard for most neural networks.  \n",
        "**Neurons/Units**: We set these to 32 to start. This is the dimensionality of the output space. Since we just want a final score differences we set the last value to 1.  \n",
        "**Input Shape**: This is the size of the data you are using to train. In our case, we have home team score, away team score, home team defense and away team defense. So, we set this value to 4.  \n",
        "**Activation** ([Documentation](https://keras.io/api/layers/activations/#relu-function)): We picked Recified Linear Unit (relu). Using trial and error you can determine which one is best for your data. There are some activations that are for specific network results.  \n",
        "**Optimizers** ([Documentation](https://keras.io/api/optimizers/rmsprop/)): Optimizers are used during training to try and find the global optimum which will lead to better results. We chose RMSProp as a general purpose optimizer.  \n",
        "**Metrics** ([Documentation](https://keras.io/api/metrics/)): This array determines what values are tracked and returned during training. We will use these to graph our results and determine how well our model is representing our data.  \n",
        "**Loss Function** ([Documentation](https://keras.io/api/losses/)): The loss function is what is computed to determine how good or bad our output matches our expected results."
      ],
      "metadata": {
        "id": "KYFb5JmuYD7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Build_Model():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(32, activation='relu', input_shape=[4]),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.RMSprop()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model"
      ],
      "metadata": {
        "id": "QtsOInLIYNbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bballmodel = Build_Model()"
      ],
      "metadata": {
        "id": "UZwkeF_KYRXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This method will be used in place of the normal output. This is cleaner in my opinion\n",
        "class PrintDoc(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 10 == 0: print('')\n",
        "    print('.', end='')"
      ],
      "metadata": {
        "id": "amsu5jbiYUEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Complexity  \n",
        "I am going to take this section to talk about the complexity of the model as well as high bias and high variance.\n",
        "\n",
        "**Bias**: A model with low model complexity with a high error rate is said to have high bias. The high bias comes from underfitting the data.  \n",
        "\n",
        "**Variance**: A model with high complexity with a high error rate is said to have high variance. The high variance comes from overfitting the data."
      ],
      "metadata": {
        "id": "6roeoEGUYZgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Test/Validate"
      ],
      "metadata": {
        "id": "kKSn82E_YpEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data set from the previous colab (already created cleaned data)\n",
        "column_names = ['Date','HomeTeam','HomeScore','AwayTeam','AwayScore',\n",
        "                'HomeScoreAverage','HomeDefenseAverage','AwayScoreAverage','AwayDefenseAverage',\n",
        "                'Result']\n",
        "\n",
        "games_csv = 'https://raw.githubusercontent.com/ehennis/Blog/master/DeepLearningBasketball/NebraskaCode/Data/Games-Calculated.csv'\n",
        "all_data = pd.read_csv(games_csv, header=None, names=column_names)\n",
        "all_data.head()"
      ],
      "metadata": {
        "id": "SgK4GgIRYapc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Train/Test/Validate data sets  "
      ],
      "metadata": {
        "id": "6_QpXqvkaxCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### All about data  \n",
        "When training a network we need to send in data for it to learn. We can't then use the same data to test if it is learning. It would be like working a problem in school and then get that same problem on the test. All it proves is you know that data. We need the model to generalize the data versus knowing the actual data.\n",
        "\n",
        "**Generalization** is a term used to describe the model's ability to understand new data it hasn't seen before. In this project, we need to generalize to all games in the future versus the individual games in the past. When the model doesn't generalize it gets into a scenario where it overfits.  \n",
        "\n",
        "**Overfitting** is a term used to describe when the model only learns the data it has versus the new data. You can see this visually in the graph of the errors resulting from training. You will see that your training errors will decrease while your validation errors will start to increase again.  \n",
        "\n",
        "### Splits  \n",
        "As stated above, we need to ensure we don't overfit to the data. To handle this we need to separate the data into 3 data sets (With the way Keras handles the validation within the network we only create 2). In my example, I used 80% of train (which will get split 80/20 for validation) and 20% for testing. This allows me plenty of randomized data to test my model.  \n",
        "\n",
        "### Data Labels  \n",
        "You will notice that I remove the *Results* column and name those as the labels. The labels are used as the answers or truth in the network. When the network gets the data it will then try and predict its own label and compare it versus the correct label. After they get the error (we use mean square error) it uses an algorithm called backpropagation to go back through all the weights and biases in the nodes to attempt to get the answer correct next time.  \n",
        "\n",
        "### Data Normalization  \n",
        "At the end of the code I normalize all of the data. The reason for me doing this is to ensure that the scale of the values are all similiar. If our first input ranges from 30 to 120 and the second input ranges from 2 to 10 the first input will have an outsized impact on our learning."
      ],
      "metadata": {
        "id": "Zvdac4HfYzWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the columns that we are NOT going to train on\n",
        "all_data.drop(['Date','HomeTeam','HomeScore','AwayTeam','AwayScore'], axis=1, inplace=True)\n",
        "all_data.tail()\n",
        "\n",
        "#Break it into 80/20 splits\n",
        "train = all_data.sample(frac=0.8, random_state=0)\n",
        "test = all_data.drop(train.index)\n",
        "print('Training Size: %s' % train.shape[0])\n",
        "print('Testing Size: %s' % test.shape[0])\n",
        "\n",
        "#Create the labels\n",
        "train_labels = train.pop('Result')\n",
        "test_labels = test.pop('Result')\n",
        "\n",
        "# Normalize the data\n",
        "mean = train.mean(axis=0)\n",
        "train_data = train - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data = test - mean\n",
        "test_data /= std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5we3jlQTY6LK",
        "outputId": "03e756d2-4c14-4ecf-c612-1a7670242005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Size: 16128\n",
            "Testing Size: 4032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "**Parameter**  \n",
        "`fit` ([Documentation](https://keras.io/api/models/model_training_apis/#fit-method)): Fit is the method that does the training. We pass in our training values, our expected results, the number of epochs to train, the validation split, the level of logging, and finally we pass in our printing method."
      ],
      "metadata": {
        "id": "PomOf0uCY9uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = bballmodel.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIzSJYQNZJSB",
        "outputId": "27c660cd-8453-43cb-f5d1-5f12c242b6e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            ".........."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "# Create a DataFrame from the output from the fit method\n",
        "hist = pd.DataFrame(history.history)\n",
        "# Create an epoch column and set it to the epoch index\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zsXarySKZM91",
        "outputId": "1410e720-dc56-4096-a139-e137cb83c757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         loss  mean_absolute_error  accuracy  mean_squared_error   val_loss  \\\n",
              "95  90.679527             7.301902       0.0           90.679527  85.906212   \n",
              "96  90.670853             7.299296       0.0           90.670853  86.134315   \n",
              "97  90.580666             7.294621       0.0           90.580666  85.861504   \n",
              "98  90.694855             7.302468       0.0           90.694855  86.201981   \n",
              "99  90.678871             7.296271       0.0           90.678871  85.584167   \n",
              "\n",
              "    val_mean_absolute_error  val_accuracy  val_mean_squared_error  epoch  \n",
              "95                 7.126376           0.0               85.906212     95  \n",
              "96                 7.136374           0.0               86.134315     96  \n",
              "97                 7.127809           0.0               85.861504     97  \n",
              "98                 7.145713           0.0               86.201981     98  \n",
              "99                 7.118531           0.0               85.584167     99  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50698326-7319-48bb-bdeb-ed56abf837c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>90.679527</td>\n",
              "      <td>7.301902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.679527</td>\n",
              "      <td>85.906212</td>\n",
              "      <td>7.126376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.906212</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>90.670853</td>\n",
              "      <td>7.299296</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.670853</td>\n",
              "      <td>86.134315</td>\n",
              "      <td>7.136374</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.134315</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>90.580666</td>\n",
              "      <td>7.294621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.580666</td>\n",
              "      <td>85.861504</td>\n",
              "      <td>7.127809</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.861504</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>90.694855</td>\n",
              "      <td>7.302468</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.694855</td>\n",
              "      <td>86.201981</td>\n",
              "      <td>7.145713</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.201981</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>90.678871</td>\n",
              "      <td>7.296271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.678871</td>\n",
              "      <td>85.584167</td>\n",
              "      <td>7.118531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.584167</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50698326-7319-48bb-bdeb-ed56abf837c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50698326-7319-48bb-bdeb-ed56abf837c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50698326-7319-48bb-bdeb-ed56abf837c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph the results"
      ],
      "metadata": {
        "id": "v2NBm9LDZQ6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Absolute Error')\n",
        "  plt.plot(history['epoch'], history['mean_absolute_error'],\n",
        "           label='Train Mean Absolute Error')\n",
        "  plt.plot(history['epoch'], history['val_mean_absolute_error'],\n",
        "           label = 'Val Mean Absolute Error')\n",
        "  plt.legend()\n",
        "  #plt.ylim([0,1])\n",
        "  plt.show()\n",
        "\n",
        "plot_history(hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "n3-IOXTVZPxb",
        "outputId": "d6b74c6a-cfdd-497f-ea27-b79b2569f2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph Meaning  \n",
        "Your graph might vary but there are certain things that I like to look at when determining if my network is up to the standard expected.  \n",
        "1. Overfitting: Does the validation error graph start to increase at the end. If it starts going up we have trained too much  \n",
        "2. Epochs: Do I need to train longer or shorter. In my case, my validation error levels off around 20 epochs. I could look into uses less epochs.\n",
        "3. Error Rate: After I make sure that my training looks good I check to see if the error rate is acceptable. 7 points of variance is quite a lot when it comes to a basketball game. That is the difference between a win and losing by 6. But, since humans are involved and I don't have unlimited resources I am happy with this value. In a later milestone we do some tuning to try and lower this."
      ],
      "metadata": {
        "id": "_gKUyVVlZW1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overfitting"
      ],
      "metadata": {
        "id": "WvUJvKpdZ6ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overfitmodel = Build_Model()\n",
        "history_overfit = overfitmodel.fit(train_data, train_labels, epochs=1000, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBUHB7YYaERD",
        "outputId": "ea5473b4-ca74-4c21-d4f0-5771a0187310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "..........\n",
            "....."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "# Create a DataFrame from the output from the fit method\n",
        "hist_overfit = pd.DataFrame(history_overfit.history)\n",
        "# Create an epoch column and set it to the epoch index\n",
        "hist_overfit['epoch'] = history_overfit.epoch\n",
        "\n",
        "plot_history(hist_overfit)"
      ],
      "metadata": {
        "id": "W14sdYl9aPif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper Parameter Tuning"
      ],
      "metadata": {
        "id": "YHACr8d1bCLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unless you are lucky, your first model architecture won't be perfect. This milestone is attempting to find the optimal parameters for your neural network. Below, I will try with different layers, different neuron counts, and different activation functions.  \n",
        "\n",
        "First, I am going to try different amounts of neurons in the layers. From there, I will take the winner and change the activation function. Once I have that picked out, I will change the optimizer.\n",
        "\n",
        "### Layers and Neurons  \n",
        "We can adjust the complexity of the model but varying the number of layers and the neurons inside of them. Our only limitation is that our input layer has to match our data and our output layer needs to give us a number.  \n",
        "\n",
        "One thing to keep in mind is that the more complexity of your model the more data it will take to generalize it. This is because the network has so many paths through it that it will give the exact result of game versus having multiple games go through that same path.\n",
        "\n",
        "### Activation Function  \n",
        "The activation function determines how each neuron is adjusted based on the error. In our case, if the expected result was 5 and the actual was 3 that means the activation function will pass in the error into its function and then adjust the neuron accordingly.\n",
        "\n",
        "We started with `relu` and will try `sigmoid` and `softmax`. \n",
        "\n",
        "**RELU**: Rectified Linear Unit. It is a very quickly converging. This function will return a positive value. Equation: $$relu(x) = max(x,0)$$  \n",
        "**Softmax**: This function will also return a postivie value but from 0 to 1. It converts a real vector to a vector of categorical probabilities. Equation: $$softmax(x_i) = \\frac{exp(x_i)}{\\sum_{0}^{k}exp(x_k)}$$  \n",
        "**Sigmoid**: This function will also return a postive value from 0 to 1. It is equivalent to a 2-element Softmax. Equation: $$sigmoid(x) = \\frac{1}{(1 + exp(-x))}$$  \n",
        "\n",
        "Available Keras activation functions: [https://keras.io/api/layers/activations/](https://keras.io/api/layers/activations/).  \n",
        "\n",
        "### Optimizer  \n",
        "**RMSProp** [Link](https://keras.io/api/optimizers/rmsprop/): Maintains a moving average of the squares of the gradients and divides the gradient by the root of this average.  \n",
        "**SDG (stochastic gradient descent)** [Link](https://keras.io/api/optimizers/sgd/): A basic gradient descent optimizer.  \n",
        "**Adam** [Link](https://keras.io/api/optimizers/adam/): Adam is based on SDG but uses adaptive estimation of the first and second order moments.  \n",
        "**Adamax** [Link](https://keras.io/api/optimizers/adamax/): Adamax is a variation of Adam based on the infinity norm.    \n",
        "\n",
        "Available Keras optimizers: [https://keras.io/api/optimizers/](https://keras.io/api/optimizers/)"
      ],
      "metadata": {
        "id": "FBEdnuHdbKKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Model\n",
        "_, orig_mean_absolute_error, _, _ = bballmodel.evaluate(test_data, test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "c6w6jczRbbzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Less Neutrons\n",
        "32 -> 24, 12, 8"
      ],
      "metadata": {
        "id": "kw2hM_CIb0hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Build_Model_24Neutrons():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(24, activation='relu', input_shape=[4]),\n",
        "    keras.layers.Dense(24, activation='relu'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.RMSprop()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model\n",
        "\n",
        "def Build_Model_12Neutrons():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(12, activation='relu', input_shape=[4]),\n",
        "    keras.layers.Dense(12, activation='relu'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.RMSprop()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model\n",
        "\n",
        "def Build_Model_8Neutrons():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(8, activation='relu', input_shape=[4]),\n",
        "    keras.layers.Dense(8, activation='relu'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.RMSprop()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model"
      ],
      "metadata": {
        "id": "E_Wu0f3Yb5-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m8 = Build_Model_8Neutrons()\n",
        "m8_history = m8.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])\n",
        "\n",
        "m12 = Build_Model_12Neutrons()\n",
        "m12_history = m12.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])\n",
        "\n",
        "m24 = Build_Model_24Neutrons()\n",
        "m24_history = m24.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])"
      ],
      "metadata": {
        "id": "sQCXSfB7b-Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab Their Results\n",
        "_, m8_mean_absolute_error, _, _ = m8.evaluate(test_data, test_labels,verbose=0)\n",
        "print('8 Neurons model: %s' % m8_mean_absolute_error)\n",
        "\n",
        "_, m12_mean_absolute_error, _, _ = m12.evaluate(test_data, test_labels,verbose=0)\n",
        "print('12 Neurons model: %s' % m12_mean_absolute_error)\n",
        "\n",
        "_, m24_mean_absolute_error, _, _ = m24.evaluate(test_data, test_labels,verbose=0)\n",
        "print('24 Neurons model: %s' % m24_mean_absolute_error)\n",
        "\n",
        "print('Milestone 3 model: %s' % orig_mean_absolute_error)"
      ],
      "metadata": {
        "id": "HLtWr--ScE45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Winner**: 24 Neurons"
      ],
      "metadata": {
        "id": "yzCtKD5ZcJLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activiation Functions\n",
        "RELU (rectified linear unit) -> Sigmoid, Softmax"
      ],
      "metadata": {
        "id": "CqC5ek6jcOSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Build_Model_Sigmoid():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(24, activation='sigmoid', input_shape=[4]),\n",
        "    keras.layers.Dense(24, activation='sigmoid'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.RMSprop()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model\n",
        "\n",
        "def Build_Model_Softmax():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(24, activation='softmax', input_shape=[4]),\n",
        "    keras.layers.Dense(24, activation='softmax'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.RMSprop()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Ry4pZsrmcYX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the networks\n",
        "msg = Build_Model_Sigmoid()\n",
        "msg_history = msg.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])\n",
        "\n",
        "msm = Build_Model_Softmax()\n",
        "msm_history = msm.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])"
      ],
      "metadata": {
        "id": "VOsc4gN0cbp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, msg_mean_absolute_error, _, _ = msg.evaluate(test_data, test_labels,verbose=0)\n",
        "print('Sigmoid model: %s' % msg_mean_absolute_error)\n",
        "\n",
        "_, msm_mean_absolute_error, _, _ = msm.evaluate(test_data, test_labels,verbose=0)\n",
        "print('Softmax model: %s' % msm_mean_absolute_error)\n",
        "\n",
        "\n",
        "print('24 Neuron model: %s' % m24_mean_absolute_error)"
      ],
      "metadata": {
        "id": "_u4g8eAuceGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Winner**: Still the 24 neurons with relu"
      ],
      "metadata": {
        "id": "YZXgCQiJcfNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizers\n",
        "RMSProp -> SDG (stochastic gradient descent), Adam, Adamax"
      ],
      "metadata": {
        "id": "nqB8-Vy2cjo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Build_Model_SDG():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(24, activation='relu', input_shape=[4]),\n",
        "    keras.layers.Dense(24, activation='relu'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.SGD()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model\n",
        "\n",
        "def Build_Model_Adam():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(24, activation='relu', input_shape=[4]),\n",
        "    keras.layers.Dense(24, activation='relu'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.Adam()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model\n",
        "\n",
        "def Build_Model_Adamax():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Dense(24, activation='relu', input_shape=[4]),\n",
        "    keras.layers.Dense(24, activation='relu'),\n",
        "    keras.layers.Dense(1)                                   \n",
        "  ])\n",
        "  \n",
        "  opt = keras.optimizers.Adamax()\n",
        "  m = [\n",
        "       keras.metrics.MeanAbsoluteError(),\n",
        "       keras.metrics.Accuracy(),\n",
        "       keras.metrics.MeanSquaredError()\n",
        "  ]\n",
        "  l = keras.losses.MeanSquaredError()\n",
        "  \n",
        "  model.compile(loss=l, optimizer=opt, metrics=m)\n",
        "  return model"
      ],
      "metadata": {
        "id": "No3jLqkscr3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the networks\n",
        "sdg = Build_Model_SDG()\n",
        "sdg_history = sdg.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])\n",
        "\n",
        "adam = Build_Model_Adam()\n",
        "adam_history = adam.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])\n",
        "\n",
        "ada = Build_Model_Adamax()\n",
        "ada_history = ada.fit(train_data, train_labels, epochs=100, validation_split=0.2, verbose=0, callbacks=[PrintDoc()])"
      ],
      "metadata": {
        "id": "GQdIM7IYctb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, sdg_mean_absolute_error, _, _ = sdg.evaluate(test_data, test_labels,verbose=0)\n",
        "print('SDG model: %s' % sdg_mean_absolute_error)\n",
        "\n",
        "_, adam_mean_absolute_error, _, _ = adam.evaluate(test_data, test_labels,verbose=0)\n",
        "print('Adam model: %s' % adam_mean_absolute_error)\n",
        "\n",
        "_, ada_mean_absolute_error, _, _ = ada.evaluate(test_data, test_labels,verbose=0)\n",
        "print('Adamax model: %s' % ada_mean_absolute_error)\n",
        "\n",
        "\n",
        "print('RMSProp model: %s' % m24_mean_absolute_error)"
      ],
      "metadata": {
        "id": "2euv9maocwaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Winner**: RMSProp activation was still the best"
      ],
      "metadata": {
        "id": "ECQ5fqrgc0dC"
      }
    }
  ]
}