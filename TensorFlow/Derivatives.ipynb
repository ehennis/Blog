{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Derivatives.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehennis/Blog/blob/master/TensorFlow/Derivatives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQvMSAjK9Qkc",
        "colab_type": "text"
      },
      "source": [
        "# Derivatives and TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x1nF1XR9EHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install TFv2\n",
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGdJNp6d-yxx",
        "colab_type": "text"
      },
      "source": [
        "## Gradient  \n",
        "When I was a kid I was really good at math. It just made sense. Then, I got to Iowa State and took their engineering style calculus and was doing well through the first 3/4th of the class. Then the teacher said that the final could only *hurt*  our scores so I phoned it in. It was one of the biggest academic mistakes of my life. It started a chain reaction that has killed me to this day. Why? I never learned derivatives.  \n",
        "\n",
        "Typically, this wouldn't be a big deal. But, I went to grad school and they are ALL over machine learning. This little notebook will try and clear up the math that never made sense to me but was so simple to everyone else that nobody explains it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFE-uWMR9YKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj7lY4I6_iL6",
        "colab_type": "text"
      },
      "source": [
        "I will set up a simple gradient using TensorFlow v2. All I am doing here is creating a 2x2 matrix, summing them (4) and the squaring them. Finally, I call the *gradient* method on them to find the derivative. As you can see you get 8 but I have never seen it explained. So, here is my attempt.  \n",
        "\n",
        "\n",
        "---\n",
        "With $y = 4$ and $z=y^2$ we are trying to figure out $\\frac{d_z}{d_y}$  \n",
        "In order to do that we need to use the `power rule` which states $x^y$ becomes $yx^{y-1}$  \n",
        "Doing that turns $y^2$ into $2y^1$ and in our case with $y = 4$ we get 8! \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE4WE4z29iYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dbaeec3-fcb8-43f7-afc6-515825b96fb6"
      },
      "source": [
        "x = tf.ones((2,2)) # [[1,1] [1,1]]\n",
        "with tf.GradientTape() as t:\n",
        "  t.watch(x)\n",
        "  y = tf.reduce_sum(x) # 4\n",
        "  z = tf.multiply(y,y) # 4 x 4 = 16\n",
        "\n",
        "dz_dy = t.gradient(z,y) # x^2 => 2x based on the power rule\n",
        "dz_dy.numpy()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aypdre0lA6B0",
        "colab_type": "text"
      },
      "source": [
        "This second example is the same as the first but we have $x = 2$, $y = x^3$, and $z$ is $\\frac{d_z}{d_y}$  \n",
        "Using the same `power rule` we change from $x^3$ to $3x^2$ and with $x = 2$ we get 12!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbxq1Xmd9rGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a105a04-d770-4341-f4ae-9fe033d9086a"
      },
      "source": [
        "x = tf.Variable(2.0)\n",
        "with tf.GradientTape() as t:\n",
        "  y = x * x * x # x^3\n",
        "  z = t.gradient(y,x) #3x^2 by the power rule\n",
        "\n",
        "z.numpy()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoCEmpyiBVXN",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion  \n",
        "I know this is SUPER simple but it was something I never understood so I put it on paper so that I would learn it and it would be here forever."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xgf6gNOBeUA",
        "colab_type": "text"
      },
      "source": [
        "Here is link with all the derivative rules: [Link](https://www.mathsisfun.com/calculus/derivatives-rules.html)"
      ]
    }
  ]
}